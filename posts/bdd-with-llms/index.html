<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Behavior-driven development with LLMs | Memo Garcia</title>
<meta name=keywords content><meta name=description content="Have you ever asked an LLM, &ldquo;Build me a CRUD API in FastAPI,&rdquo; and just hoped for the best? LLMs are great at taking broad requests and letting us talk to computers like they’re people. But that freeform style can bring surprises and make it tough to get the same result twice.
Behavior-Driven Development, or BDD, offers a clear framework. It guides you to:
Define exactly what you expect Set clear boundaries for the solution Keep everything documented in plain language Creating a prompt plan using BDD A &ldquo;prompt plan&rdquo; is basically a roadmap for your LLM."><link rel=canonical href=https://memo.mx/posts/bdd-with-llms/><meta name=google-site-verification content="G-ZRB1GGCC9B"><link crossorigin=anonymous href=/assets/css/stylesheet.d1467e28595903f993a7e37893057cefe5f69aece461c850796bf5b0a3bf422a.css integrity="sha256-0UZ+KFlZA/mTp+N4kwV87+X2muzkYchQeWv1sKO/Qio=" rel="preload stylesheet" as=style><link rel=icon href=https://memo.mx/%20favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://memo.mx/%20favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://memo.mx/%20favicon-32x32.png><link rel=apple-touch-icon href=https://memo.mx/%20apple-touch-icon.png><link rel=mask-icon href=https://memo.mx/%20safari-pinned-tab.svg><meta name=theme-color content="#0d0221"><meta name=msapplication-TileColor content="#0d0221"><link rel=alternate hreflang=en href=https://memo.mx/posts/bdd-with-llms/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZRB1GGCC9B"></script><script>var dnt,doNotTrack=!1;if(!0&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZRB1GGCC9B")}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://memo.mx/posts/"},{"@type":"ListItem","position":2,"name":"Behavior-driven development with LLMs","item":"https://memo.mx/posts/bdd-with-llms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Behavior-driven development with LLMs","name":"Behavior-driven development with LLMs","description":"Have you ever asked an LLM, \u0026ldquo;Build me a CRUD API in FastAPI,\u0026rdquo; and just hoped for the best? LLMs are great at taking broad requests and letting us talk to computers like they’re people. But that freeform style can bring surprises and make it tough to get the same result twice.\nBehavior-Driven Development, or BDD, offers a clear framework. It guides you to:\nDefine exactly what you expect Set clear boundaries for the solution Keep everything documented in plain language Creating a prompt plan using BDD A \u0026ldquo;prompt plan\u0026rdquo; is basically a roadmap for your LLM.","keywords":[],"articleBody":"Have you ever asked an LLM, “Build me a CRUD API in FastAPI,” and just hoped for the best? LLMs are great at taking broad requests and letting us talk to computers like they’re people. But that freeform style can bring surprises and make it tough to get the same result twice.\nBehavior-Driven Development, or BDD, offers a clear framework. It guides you to:\nDefine exactly what you expect Set clear boundaries for the solution Keep everything documented in plain language Creating a prompt plan using BDD A “prompt plan” is basically a roadmap for your LLM. Here’s an example:\nFeature: CRUD API for managing users Background: We're building a REST API using FastAPI. Context: - Endpoint base: \"/users\" - Language: Python 3.13 - Libraries: httpx, fastapi, pydantic, uvicorn, tortoise-orm Scenario: Creating a new user Given there's an endpoint for creating users at \"/users\" When a POST request is made with these details: - email: user@example.com - password: secure_pass Then the API returns a 201 status and user info And the user is stored in the database When you structure prompts like this, the LLM knows exactly what success looks like, making it easy to verify results.\nHow to use the prompt plan Pass your prompt directly to the LLM. Clear prompts mean clear results. You’ll quickly know whether the output matches expectations.\nLLM limitations Besides the well-known hallucination issues with LLMs, there are some major limitations:\nContext size: Even newer models have limits to how much information they can handle at once. Context awareness: LLMs start fresh with every prompt, so restating context clearly is essential. Tips for Better Results Don’t let LLMs make assumptions unless you intentionally want them to. Clearly describe your expectations. Define the style or personality if it matters. ChatGPT is not the only game in town You can also explore other models like Claude, DeepSeek, or even self-hosted solutions. Pick what suits your use case best.\nHave a clear goal in mind Techniques like BDD or TDD help keep prompts clear and goal-focused. Define exactly what you want to achieve, then craft your prompts around those specific outcomes.\nUsing a structured method like this ensures results that are predictable, repeatable, and much easier to validate.\nConclusion Behavior-driven prompt planning gives your LLM clear success criteria and makes results predictable and verifiable. By defining expectations upfront and documenting scenarios, you’ll spend less time debugging and more time delivering reliable APIs.\n","wordCount":"405","inLanguage":"en","datePublished":"2025-01-22T00:03:30+01:00","dateModified":"2025-08-12T23:15:22+09:00","author":{"@type":"Person","name":"Memo Garcia"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://memo.mx/posts/bdd-with-llms/"},"publisher":{"@type":"Person","name":"Memo Garcia","logo":{"@type":"ImageObject","url":"https://memo.mx/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://memo.mx/ accesskey=h title="Memo Garcia (Alt + H)">Memo Garcia</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://memo.mx/tools title=Tools><span>Tools</span></a></li><li><a href=https://memo.mx/dayjob title=$DAYJOB><span>$DAYJOB</span></a></li><li><a href=https://memo.mx/startup title=Startup><span>Startup</span></a></li><li><a href=https://memo.mx/youtube title=YouTube><span>YouTube</span></a></li><li><a href=https://memo.mx/books title=Books><span>Books</span></a></li><li><a href=https://memo.mx/about title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Behavior-driven development with LLMs</h1><div class=post-meta><span title='2025-01-22 00:03:30 +0100 +0100'>January 22, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Memo Garcia</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#creating-a-prompt-plan-using-bdd aria-label="Creating a prompt plan using BDD">Creating a prompt plan using BDD</a></li><li><a href=#how-to-use-the-prompt-plan aria-label="How to use the prompt plan">How to use the prompt plan</a></li><li><a href=#llm-limitations aria-label="LLM limitations">LLM limitations</a></li><li><a href=#tips-for-better-results aria-label="Tips for Better Results">Tips for Better Results</a><ul><li><a href=#chatgpt-is-not-the-only-game-in-town aria-label="ChatGPT is not the only game in town">ChatGPT is not the only game in town</a></li><li><a href=#have-a-clear-goal-in-mind aria-label="Have a clear goal in mind">Have a clear goal in mind</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></div></details></div><div class=post-content><p>Have you ever asked an LLM, &ldquo;Build me a CRUD API in FastAPI,&rdquo; and just hoped for the best? LLMs are great at taking broad requests and letting us talk to computers like they’re people. But that freeform style can bring surprises and make it tough to get the same result twice.</p><p>Behavior-Driven Development, or BDD, offers a clear framework. It guides you to:</p><ol><li>Define exactly what you expect</li><li>Set clear boundaries for the solution</li><li>Keep everything documented in plain language</li></ol><h2 id=creating-a-prompt-plan-using-bdd>Creating a prompt plan using BDD<a hidden class=anchor aria-hidden=true href=#creating-a-prompt-plan-using-bdd>#</a></h2><p>A &ldquo;prompt plan&rdquo; is basically a roadmap for your LLM. Here&rsquo;s an example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>Feature: CRUD API <span class=k>for</span> managing users
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Background:
</span></span><span class=line><span class=cl>  We<span class=s1>&#39;re building a REST API using FastAPI.
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>Context:
</span></span></span><span class=line><span class=cl><span class=s1>  - Endpoint base: &#34;/users&#34;
</span></span></span><span class=line><span class=cl><span class=s1>  - Language: Python 3.13
</span></span></span><span class=line><span class=cl><span class=s1>  - Libraries: httpx, fastapi, pydantic, uvicorn, tortoise-orm
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>Scenario: Creating a new user
</span></span></span><span class=line><span class=cl><span class=s1>  Given there&#39;</span>s an endpoint <span class=k>for</span> creating users at <span class=s2>&#34;/users&#34;</span>
</span></span><span class=line><span class=cl>  When a POST request is made with these details:
</span></span><span class=line><span class=cl>    - email: user@example.com
</span></span><span class=line><span class=cl>    - password: secure_pass
</span></span><span class=line><span class=cl>  Then the API returns a <span class=m>201</span> status and user info
</span></span><span class=line><span class=cl>  And the user is stored in the database
</span></span></code></pre></div><p>When you structure prompts like this, the LLM knows exactly what success looks like, making it easy to verify results.</p><h2 id=how-to-use-the-prompt-plan>How to use the prompt plan<a hidden class=anchor aria-hidden=true href=#how-to-use-the-prompt-plan>#</a></h2><p>Pass your prompt directly to the LLM. Clear prompts mean clear results. You&rsquo;ll quickly know whether the output matches expectations.</p><h2 id=llm-limitations>LLM limitations<a hidden class=anchor aria-hidden=true href=#llm-limitations>#</a></h2><p>Besides the well-known hallucination issues with LLMs, there are some major limitations:</p><ol><li>Context size: Even newer models have limits to how much information they can handle at once.</li><li>Context awareness: LLMs start fresh with every prompt, so restating context clearly is essential.</li></ol><h2 id=tips-for-better-results>Tips for Better Results<a hidden class=anchor aria-hidden=true href=#tips-for-better-results>#</a></h2><ol><li>Don&rsquo;t let LLMs make assumptions unless you intentionally want them to.</li><li>Clearly describe your expectations.</li><li>Define the style or personality if it matters.</li></ol><h3 id=chatgpt-is-not-the-only-game-in-town>ChatGPT is not the only game in town<a hidden class=anchor aria-hidden=true href=#chatgpt-is-not-the-only-game-in-town>#</a></h3><p>You can also explore other models like Claude, DeepSeek, or even self-hosted solutions. Pick what suits your use case best.</p><h3 id=have-a-clear-goal-in-mind>Have a clear goal in mind<a hidden class=anchor aria-hidden=true href=#have-a-clear-goal-in-mind>#</a></h3><p>Techniques like BDD or TDD help keep prompts clear and goal-focused. Define exactly what you want to achieve, then craft your prompts around those specific outcomes.</p><p>Using a structured method like this ensures results that are predictable, repeatable, and much easier to validate.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Behavior-driven prompt planning gives your LLM clear success criteria and makes results predictable and verifiable. By defining expectations upfront and documenting scenarios, you’ll spend less time debugging and more time delivering reliable APIs.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://memo.mx/posts/happiness/><span class=title>Next »</span><br><span>Happiness</span></a></nav></footer></article></main><footer class=footer></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>