
 There are specialized buildings: a library building might represent a university network, a bank vault building might be a secure banking network, a shopping mall could be an e-commerce network. On the internet, you have all sorts of specialized networks (gaming networks, streaming networks, etc., each optimized for certain tasks).

All these diverse buildings are connected by roads, highways, and bridges. In the world of the internet, the “roads” are the physical and wireless links: fiber optic cables running under the ocean, telephone lines, satellite links, Wi-Fi signals, etc. These are what connect one network to another. Just like roads connect buildings and let vehicles carry mail or people around, these data links carry packets between networks.

Imagine looking at a map of a city at night with lights representing buildings and roads connecting them. The internet is similar, though on a much grander scale:

 Local roads might be the smaller-scale connections (like the cable from your home router to your ISP, or the Wi-Fi and Ethernet connecting machines in an office).

 Highways are like the backbone connections, maybe fiber lines that run between cities or under oceans connecting continents.

 Bridges could be special links like satellite connections or cross-ocean cables bridging big gaps.

With so many “buildings” and such a huge “city,” how do we ever find anything? It would be like trying to find one specific apartment in a metropolis of 10 million buildings! This is where our navigation tools – addresses, directories (DNS), and routers acting like traffic control – are crucial on a larger scale.

Key point: The internet has no single central building or central road – it’s a network of networks
cs.utexas.edu
. Each network (building) often belongs to an entity (an individual, a company, an institution, an ISP, etc.), and they agree to connect their networks following common standards (like using IP, BGP for inter-network routing, etc.) so that data can flow between them.

So, when you send data from your device in your home network to a server in another country, you’re essentially sending a message from your little building, through the streets, onto the highway, possibly switching highways, exiting into another neighborhood, and finally arriving at the destination building overseas. You rely on things analogous to traffic signs, maps, and postal services at the city scale – which in internet terms are routing protocols, address schemes, and ISP infrastructures – to get it there.

The complexity is astounding, but like a city, it’s somewhat organized: There are major “hubs” where data tends to flow (like Internet Exchange Points, analogous to major postal centers or highway interchanges), and there are smaller routes connecting out-of-the-way “villages” (maybe a remote network connecting via a few hops to the nearest big hub).

In the next sections, we’ll talk about how data is routed through this city (routers as our maps and traffic cops on the journey), and who builds and maintains these roads (ISPs), etc.

But as an image, hold the thought: The internet = a global city of networks
, all cooperating (most of the time) to deliver data anywhere it needs to go.
Technical Perspective: The internet being a “network of networks” is not just a metaphor, it’s the literal definition. Each building = an autonomous system (AS) or just a local network. The connections between networks are managed by Internet Service Providers (ISPs) and governed by protocols like BGP (Border Gateway Protocol), which is the “routing protocol of the internet” that lets one network announce to others what destinations (IP prefixes) it can deliver to. There’s hierarchy (though somewhat flattening in recent times) in how networks connect:

 Your home network connects to a local ISP (maybe a regional provider).

 That ISP might connect to a larger national ISP or directly to major exchange points.

 Large content providers (like Google, Netflix, etc.) have their own global networks (their own “buildings” and highways) which peer with ISPs.

 At certain locations called Internet Exchange Points (IXPs), many networks meet to swap traffic (like a big interchange in a highway system)

 There are also submarine cables connecting continents, which are like the trans-oceanic highways.

 The city has no single mayor: no one entity controls the whole internet, but many coordinate via standardization bodies (IETF, ICANN for addresses and names, etc.) to keep it running smoothly.

The scale: There are billions of devices (rooms) and hundreds of thousands of networks (buildings). IP addressing (IPv4 and IPv6) provides the addressing scheme to uniquely identify each endpoint globally (like unique building + room combos globally for public addresses), which is why we needed IPv6 as IPv4 addresses ran out.

Data traveling through the internet often passes through multiple autonomous systems; each hop is a router at the edge of one network passing it to a router at the edge of another. You might traceroute a packet and see 10-15 hops through different providers and locations.

Reliability: The packet-switched design and redundant paths make the internet resilient. Even if part of the “city” suffers a power outage (say a major fiber is cut in a region), routers recalc routes and find detours if possible (though with some slowdown, analogous to traffic being re-routed around an accident).

So, conceptually, seeing the internet as a huge city is helpful to appreciate that your data doesn’t magically teleport from point A to B – it travels through a complex web of infrastructure, akin to navigating a huge sprawling metropolis with many stops, intersections, and signs along the way.
Routers as City Maps

We already saw routers as building concierges guiding between floors. When we scale up to the city (internet), routers take on an even more crucial role: they become the map-keepers of the internet.

Imagine driving in a massive city. At every major intersection, you might have signs or traffic lights. In networking, routers act a bit like those intersection guides – but smarter. Instead of static signs, they dynamically exchange information and decide the best path for each packet.

Inside your building (local network), your router had a simple job: know where Floor 5 is, know where Floor 3 is, etc. But in the city, a router (especially those big core routers in ISPs) needs to know about thousands of networks (like thousands of buildings addresses) or at least how to reach them.

Routers in the internet are connected to each other forming a web. They share with each other what they know via routing protocols:

 One router might tell its neighbor, “Hey, I have a route to Network A over here, through me.” The neighbor updates its map.

 They communicate through protocols like BGP (between organizations) or OSPF/RIP (within an organization) to keep their maps current.

So when a packet arrives at a router, the router essentially looks at its internal “city map” (the routing table) and says: Destination is Building X? According to my map, the fastest (or configured) route to that is via Road Y – so I’ll forward the packet to the next router down Road Y. Each router repeats this process, so the packet is handed off like a baton from one to the next, moving closer to the destination.

The idea of routing tables is key – it’s like each router has a GPS with the latest traffic info. If a road (connection) goes down, routers detect it (maybe via neighbors not talking anymore, akin to hearing that a highway is closed) and they update their maps to avoid that route
. If a new road is built (a new link between networks comes up), they learn a new route and might take advantage of it if it’s better.

So routers in aggregate ensure that even if the city roads are complicated, you (as a data packet) don’t have to figure out the whole path from start to finish; you just rely on the routers at each step to point you in the right direction. That’s akin to driving and at each intersection having a sign that directs you toward the district you’re aiming for, rather than memorizing the entire route.

Another way to visualize: if the internet is a city, the routers are like distribution centers or post offices that know where to send mail next. A local post office might not know the exact carrier route for the destination, but it knows to send this batch of mail to the central processing center; the central one knows to send it to the right regional center, and so on. Each step is guided by a “routing” decision until it reaches the post office nearest the destination, which then knows the local route.

In simpler analogies: routers in the global context act like a chain of street signs and direction pointers
. Without them, your packet would be lost in the city. With them, even if one route is blocked, often another route can be found (maybe longer, but it gets there).

So next time you’re streaming a video, realize that dozens of routers across various countries might be collaborating to get those video packets to you quickly. They are constantly updating their maps (especially at the big scale, BGP updates when networks change paths, etc.) to ensure the city’s data traffic flows efficiently.
Technical Perspective: At the global scale, routers use protocols like BGP (Border Gateway Protocol) to exchange reachability information. BGP essentially allows networks (Autonomous Systems) to advertise “I can reach these IP prefixes” to other networks. It’s often compared to a vectoring system for routes – it’s not purely shortest path like road distance; policies and path preferences come into play. However, conceptually each router ends up with a routing table entry for every network prefix it might need to send traffic to (or a default route for smaller routers). High-end routers can have routing tables with on the order of >800,000 IPv4 routes (as of mid-2020s) plus a bunch of IPv6 routes. They use this table to perform a longest prefix match on destination IP of each packet and decide which interface to send it out on (which is the next hop towards that destination). This is done extremely fast in hardware (TCAMs and such for lookup).

Inside a large network (like within an ISP or large enterprise), IGPs (Interior Gateway Protocols) like OSPF or IS-IS might be used to propagate routes internally, and those are more akin to having the detailed map of the company's own roads. BGP is more like inter-company exchange of routes (the big highway map).

Routers also implement various algorithms for picking routes: some prefer the shortest AS path (BGP’s default is basically that), others consider link costs or speeds. They can also detect failures via keepalive messages and routing protocol signals, and then recalc routes typically within seconds (sometimes faster, sometimes a bit slower for BGP).

In summary, think of the internet’s routing system as a combination of millions of “street signs” (the routing entries) and agreements like “if you see traffic for my area, send it my way and I’ll handle it from there” (peering agreements between networks).

One last point: In a city, if too many cars try to use one road at once, you get a jam. On the internet, if too much data tries to use one link at once, you get congestion (packets queue up, and if queue is full, new ones get dropped). This is where routers might also act like traffic police by implementing QoS or traffic shaping, and protocols like TCP react to drops by slowing down. So the routing system plus these congestion control mechanisms are what keep the internet running relatively smoothly even during peak usage times – akin to smart traffic lights and perhaps metering ramps on highways to prevent total gridlock.

Next, let’s talk more about those traffic jams and detours.
Routing Tables

To expand a bit on the routers’ map analogy: the actual “map” inside each router is the routing table. If you’ve ever used a paper map or a mapping app with a list of directions, a routing table is somewhat like that but in a very abstract way.

A routing table is basically a list of known destinations (or destination patterns) and instructions on how to reach them. In the city sense:

 Destination could be a particular building or a street.

 Instruction might be “take the 5th Avenue till Main St, then turn...” – but routers simplify this by just telling the next hop (the next intersection or the next post office to hand off to).

In more concrete terms, an entry in a routing table might say:

 Destination: 203.0.113.0/24 (this denotes an entire network of addresses, similar to saying “all addresses on Elm Street block”).

 Next Hop: via 198.51.100.4 (this is the IP address of a neighboring router that knows how to get to that network).

 Possibly also Interface: eth0 (meaning send out on a specific interface/port).

So when a router gets a packet, it looks up the destination IP in its routing table. The routing table is sorted by specificity – it finds the most specific matching route (longest prefix match). For instance, a router might know a general route for “anywhere in that city goes east” but a more specific route for “this particular district in that city goes north first then east.” It will pick the specific one if available.

To the analogy: if you have a map, you might have a general idea “to get to any address with ZIP code 12345, head along Highway X.” But if you have a detailed map for one neighborhood in that ZIP, you might go a slightly optimized way once you identify the exact street.

Routers keep these tables updated via those routing protocols we mentioned:

 If a road closes, the entry might be removed or changed (e.g., “destination Elm Street now unreachable or now via a different neighbor”).

 If a new faster road opens, maybe a new entry appears preferring a new next hop.

Because these tables are the key to navigation, updating them quickly when things change is crucial. This is why there’s a lot of engineering in routing protocols to converge (update all routers with changes) as fast as possible to avoid black holes or loops.

Think of a scenario: A main fiber line between two cities goes down suddenly (like a main highway closed). The routers that used that as the next hop to some set of destinations will notice and “erase” those routes, or find alternatives. During that update period (maybe a few seconds or more, depending), some packets might be lost or find no route – akin to travelers reaching a “Road Closed” sign and having no detour instructions yet. But soon, alternative routes propagate and packets start flowing a different way (perhaps through another city). That’s like your GPS finding a new route when it detects traffic.

Routing tables can be very large – on the order of hundreds of thousands of entries for internet backbone routers. But each entry is just a destination prefix (like a network address and mask) and the next hop info, plus perhaps some metrics (like how “far” or what the preference is).

A small analogy from everyday tech: On your own PC or phone, you also have a routing table, albeit tiny. Usually it says “any address not on my local network, send to my default gateway (router).” That’s one entry (the default route). And perhaps one for local network, one for loopback. In a home, your router’s table might be only slightly more complex – mostly forwarding everything to the ISP and handling local ones directly. But an ISP’s router has to differentiate between many, many networks.

In summary, a routing table is like the collection of all known paths a router can use, and picking the best one for each packet is how data finds its target without an explicit end-to-end guide pre-written.
Technical Perspective: Routing tables in routers contain prefixes (network addresses with subnet masks) and their associated forwarding information (next-hop and outgoing interface). For example:

 0.0.0.0/0 via 198.51.100.1 on eth0 – this is a default route (matches anything not more specific).

 203.0.113.0/24 via 198.51.100.4 on eth1 – a specific network route.

 10.5.0.0/16 dev eth2 – perhaps an internal network reachable directly on a local interface.

Routers perform a longest prefix match on the destination IP of each packet. Modern routers do this in hardware for speed. In the early internet days, routing tables could be managed manually or with simpler protocols (RIP etc.), but with scale, BGP updates these entries dynamically for external routes.

Also, each route might have attributes: in BGP, for instance, there’s local preference, AS path, MED, etc., which influence selection when multiple routes exist for the same prefix. But ultimately once selection is done, one entry is installed in the forwarding table (FIB – forwarding information base).

Routing vs Forwarding: Technically, the “routing table” is sometimes considered the RIB (routing information base) with all known routes, and the “forwarding table” is the subset of routes the router is actively using to forward packets. In many cases, these distinctions aren't visible externally, but it’s good to know internally routers may keep additional info.

For a network engineer, understanding the routing table is vital: netstat -r or ip route on Linux shows the routing table – if something isn’t working, maybe there’s no route or a wrong route. On a big router, one might inspect BGP table entries to see if a prefix is learned or filtered.

Example: If you try to reach an IP and get “Destination net unreachable”, often it means there’s no matching route in the table (so the packet gets dropped and an ICMP message is returned). Or if there’s a misconfiguration, packets might loop because routing tables on two routers send the packet to each other back and forth – that’s a routing loop, usually protocols have methods to prevent those (like hop counts, split horizon, etc.).

In summary, routing tables are the implementation of the “knowledge” that routers use to steer traffic. They are built from initial configs, direct connections, and dynamically from routing protocols. They are as critical to networks as a brain is to a body – without them, the network wouldn’t know where to send anything.
Traffic and Detours

Even in well-planned cities, sometimes the usual routes get overwhelmed or blocked. Rush hour hits and the main highway is jammed. An accident closes a key intersection. Smart travelers (or navigation apps) will look for detours to avoid the congestion. The internet similarly experiences “rush hours” and accidents (outages), and routers must handle these gracefully by finding alternate routes.

Let’s talk traffic jams: In the network context, a traffic jam happens when a particular link or route is carrying more data than it can handle comfortably. Remember, each physical link (like a cable or fiber) has a maximum capacity (bandwidth). If devices send more data than the link can transmit at once, a queue forms at the router’s interface. If the queue gets too large, packets start getting dropped. This is analogous to cars backed up in a long line or even being turned away if an off-ramp is full.

Congestion and detours: Good news – as we discussed, routers are constantly sharing information. If a route becomes slow or fails, routers can try alternative paths
. In dynamic routing protocols, they might not detect slight congestion (they aren’t like Waze measuring minor slowdowns in real-time), but they do detect failures. However, some modern networks and systems (and adaptive protocols like some SD-WAN technologies) can react to performance metrics too.

Basic internet routing (BGP) doesn’t automatically reroute due to congestion – it’s more about availability (is the route up or down). But congestion is often handled by the endpoints adjusting (TCP slows down). However, in some cases, if one path is too slow consistently, network engineers might reconfigure routing, or traffic might naturally spread out if multi-path routes exist.

A relatable scenario:

 If a primary route between New York and Los Angeles is very crowded, data might also flow via a different path (maybe via Chicago or even a more roundabout path) especially if some smart routing or load balancing is in play. The internet often has multiple redundant links between major areas, so traffic can distribute (some networks use equal-cost multi-path routing to split load across multiple links).

The resilience aspect: If a major fiber cut happens (like an “accident” closing the road), routers quickly announce “we lost that road” and all traffic shifts to other available roads (even if longer). Your data might take a few milliseconds longer to arrive due to a detour, but it will get there. This is like having multiple bridges out of a city – one goes down, you use the other.

We can also think of traffic engineering: big network operators sometimes plan alternate paths or throttle certain traffic so that the “VIP lanes” (for critical traffic) are clear. This goes into QoS territory which we’ll hit later, but it’s akin to city planners designating some lanes as HOV or having traffic cops redirect flows during events.

The key idea to convey: The network is not static. It deals with varying loads all the time. When you stream a popular live event, that’s like rush hour – tons of data heading to many users, causing spikes in traffic. Networks mitigate this by having fat “highways” for backbone connections and by distributing content (CDNs, which we’ll discuss) closer to users. When spikes do cause congestion, protocols like TCP ensure that everyone slows down a bit (involuntarily, through packet loss signals) so that it doesn’t collapse the network.

Meanwhile, if something knocks out part of the network (like a key router goes offline or cable breaks), routing protocols re-route around the failure, much like a well-designed road system with multiple redundancies.

All of this is why you rarely notice when something happens. There have been instances (some big outages make the news) where a major internet backbone goes down and suddenly things are slow or unreachable until rerouted. But often, the network “self-heals” so quickly that end users have no clue, or just a brief glitch.

So think of internet routers and the architecture as having built-in “detour planning” capabilities. It’s not always perfect – there can be bottlenecks if, say, all alternate routes are also near capacity, but generally the philosophy is: multiple paths exist; if one is clogged, use another
. And if all are clogged, well, that’s like a city in gridlock – at that point, nothing to do but wait or improve infrastructure (upgrade links).
Technical Perspective: There are a few technical angles to congestion and detours:

 Congestion Control: This is primarily handled by transport protocols like TCP. TCP’s algorithms (like Reno, Cubic, BBR, etc.) detect packet loss or delay (as signals of congestion) and adjust sending rates. This is like drivers noticing brake lights and slowing down to avoid collisions.

 Traffic Engineering: Network operators can influence routing to balance load. For example, with BGP, an ISP might have multiple links to another ISP and can tweak route advertisements or use protocols like MPLS with traffic engineering to spread traffic. It’s like manually directing some traffic onto an alternate highway to prevent overuse of one.

 Fast Reroute: Some networks employ fast reroute mechanisms (especially in MPLS or modern routing protocols) to switch to backup paths in sub-second time if a failure is detected, improving on the often slower convergence of standard BGP.

 Multiple Paths: Protocols like ECMP (Equal-Cost Multi-Path) allow routers to use multiple next-hops for the same destination prefix if they have equal cost, effectively load-balancing traffic across parallel links. So if two roads are equally good, traffic is split – that’s proactive detour usage.

 Detour in application: Sometimes the application or overlay networks handle it – e.g., Tor or some VPNs can route around heavy nodes, or things like Google’s QUIC (on UDP) can migrate to different network paths if needed without breaking the connection.

A real example: When a big undersea cable broke between, say, Asia and North America, traffic rerouted through other cables, though latency increased (since maybe it had to go via Europe or something). That’s a detour: longer path but connectivity maintained.

Another example: BGP misconfiguration can cause traffic to detour in unintended ways (like that time when a Pakistan ISP accidentally announced a route for all of YouTube’s traffic and sucked it into a black hole – the “detour” was catastrophic because it was a mis-route). So proper functioning relies on routers exchanging accurate info.

The phrase “the internet routes around damage” is a famous saying. It’s generally true: built-in redundancy and dynamic routing allows it to circumvent many problems.

So, network reliability comes not just from strong cables, but from smart routing and protocols that adjust to conditions. This adaptability is one of the internet’s greatest strengths.
A Global Network

From a tiny room to a floor to a building to a city – we’ve scaled the analogy up and up. Let’s take a moment to marvel at what we’ve got now: a global network that connects virtually every corner of the world. From your single computer in a dorm room or a café, you can reach servers and devices on the other side of the planet in seconds. How is this even possible? Because of all the principles we’ve covered working together in harmony:

 Unique addressing (IP): Every “building” has an address and every “room” inside it can be uniquely identified. This is like having a global postal code system that ensures even in a gigantic world city, a given address points to exactly one location.

 DNS (directories): If you prefer names to addresses, the DNS system is ready to translate. This is critical because humans can’t remember billions of numeric addresses. The DNS hierarchy, like a giant international directory, is always there to help route your message by name.

 Protocols (common rules/languages): No matter if the two devices have different hardware or are across oceans, they talk in agreed languages like TCP/IP, HTTP, etc. This is akin to standardizing communication – like if everyone in the world learned a common tongue for business, or at least the postal offices all agree on how to format an envelope and address.

 Routers and Gateways (connecting infrastructure): These are the bridges and roads that link all networks. They figure out the path, whether it’s short (to the next city) or long (across continents). The cooperative nature of internet service providers and backbone carriers means your data can hop through many owners’ networks seamlessly. Just as you can drive your car across state lines and country borders following highways, your data travels across many network boundaries guided by BGP and peering agreements.

 Private/Public IP and NAT: This allows the global network to scale by not needing a public identity for every device, and provides some isolation. It’s like in a global phone system, not every office phone has a direct external line – many share a few lines through a PBX. NAT at your home or office ensures multiple devices share one public address, conserving the global address space.

 Security measures (firewalls, encryption): Though not explicitly detailed yet in our analogy, note that as data travels, there are checkpoints and locks (we’ll soon discuss security) that ensure not just anyone can barge into your building or eavesdrop on messages. On the internet, technologies like TLS (for encryption) and firewalls (for network security) are the guardians of safe transit.

 Coordinated operation: The fact that no single entity runs the whole internet, but it still works, is like a city with no single mayor yet everything somehow functions – because everyone follows common laws (protocols) and mutual agreements (ISPs peering, etc.). There are organizations (like IETF, ICANN, etc.) which set standards and coordinate critical resources like addresses and domain names to avoid chaos.

When we say “global network,” we also underscore the speed and capacity. Light travels fast – and through fiber optics, your data literally travels as light, at two-thirds of the speed of light approximately. This means even around the world (~40,000 km), theoretically ~0.2 seconds one-way for light in fiber, maybe ~0.3 seconds after all the switching. That’s why you can have nearly real-time video calls with someone across the planet. It’s like having a conversation with someone in the next room, except the “next room” is in another country.

It’s also robust: if one route is down, others pick up. If one server is busy, others might share load (think of content delivery networks replicating content across the globe, which we’ll mention soon). The design is not perfect, but it’s incredibly resilient given its scale and decentralization.

So, from our analogy perspective: now we have a worldwide cityscape where any room can send a message to any other room, across any distance, and the message can get there usually in less than a second. That’s the power of the internet, built on the networking fundamentals we’ve covered.
Technical Perspective: The internet’s global nature relies on:

 IP (Internet Protocol) as the universal addressing scheme (IPv4 and IPv6 ensuring that every network node can be identified globally, the latter solving the address exhaustion issue).

 Standard protocols (TCP, UDP, etc.) that all systems implement – thanks to standards (RFCs) and interoperable implementations.

 Physical infrastructure: huge amounts of fiber optic cabling, undersea cables (with repeaters), satellite links, cellular networks, etc., that physically move the data. Companies and governments invest in this continuously (adding more fiber, increasing backbone speeds, launching new satellites).

 Agreements and governance: e.g., Tier 1 ISPs that form the core don’t charge each other (settlement-free peering) to exchange traffic, ensuring global reachability. They do charge lower tiers, etc., but the system overall ensures that any internet user can reach any other, as networks are motivated to be interconnected (who’d join an internet that can’t reach half the world?).

 The speed: as noted, signals propagate near light speed. There’s also optimization: new protocols reduce handshake overhead (like QUIC vs TCP for repeated connections), smarter routing caching, etc. Hardware improves so routers can forward at terabits per second rates.

 Scale: global internet traffic is in the zettabytes per year range now. It’s handled by distributed architecture (no single wire or router carries it all – it’s spread out). Content is served from multiple data centers around the world to shorten distances (CDNs, more later). That’s like in our city, having copies of a library’s popular books in many branches so people don’t all travel to one big central library.

To put it in a frame: The Internet is the largest engineered system ever built by humans, linking billions of devices. And it works 24/7, largely invisibly to us. It embodies the principle that if you design simple, robust building blocks (like IP being dumb about content, just forwarding packets; TCP handling reliability; DNS handling naming; etc.), and allow many participants to cooperate through open protocols, you can scale to an unimaginable extent.

We’ve now covered the core of how data gets from here to there. Next, we’ll delve into some additional important aspects of networks, like who provides these links (ISPs), and things about security, performance enhancements, etc., all within our trusty analogy framework.
ISPs as Builders

Let’s focus on the role of those who actually construct and provide the roads in our city-of-networks: the ISPs (Internet Service Providers). In our building analogy, if each building is a network, how do they get connected physically? Someone has to lay down the cable (the roads) between buildings, maintain them, and possibly regulate traffic. This is what ISPs do in the digital world.

Think of ISPs as the construction companies and utility providers of the internet city
:

 They lay the cables (fiber optic lines underground, coaxial cables to homes, etc.) that serve as the main roads and highways between networks.

 They may own routers and switching centers that act like the big highway interchanges or bridges connecting different parts of the city.

 They provide service to buildings (networks) much like a utility. When you get internet access at home, you’re essentially hiring an ISP to connect your home (your building) to the rest of the global city. Without that, your building is isolated – you’d have a network, but it’d be like a building with no road leading to it.

 In many places, multiple ISPs might serve the same area, analogous to multiple road companies or tollway operators. They interconnect at exchange points.

On a more granular note, consider your home network (a small building) connecting to your ISP:

 The ISP gives you a “last mile” connection – maybe a fiber line or DSL or cable line into your building. This is like them building a private driveway from your house to the main road.

 At the other end, the ISP connects up to larger networks (or is itself large). They might be connected to other ISPs regionally, and those to others globally. ISPs themselves form a hierarchy or mesh (there are Tier 1 ISPs that form the internet backbone, Tier 2 that connect regions or countries but pay Tier 1 for wider access, Tier 3 that directly serve consumers or local areas, etc.).

So when you send data out, after leaving your building via the gateway, you’re on the ISP’s infrastructure – their roads. They ensure your data can travel along their network and then hop off to another ISP’s network if needed to reach the destination building.
